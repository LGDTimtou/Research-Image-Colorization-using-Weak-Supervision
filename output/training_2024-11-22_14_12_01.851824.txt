Training on cuda
batch size: 32
#epochs: 20
learning rate: 0.001
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)
loss function: SmoothL1Loss()
user input simulation variables:
 - distribution: SamplingOption.GAUSSIAN
 - n: 20
 - p: 2